---
title: "CTRU R Functions"
author: "n.shephard@sheffield.ac.uk"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{CTRU R Functions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

[Sheffield Clinical Trials Research Unit]() conducts clinical trials of different medical and therapeautic interventions.  The Standard Operating Procedures (SOPs) state that work should be conducted in a reproducible manner to which end software such as [R](https://www.r-project.org) or [Stata](https://www.stata.com/).  Many of the tasks involved in performing the statistical analysis are common across the studies conducted, for example the bespoke database system [Prospect](https://www.ctru-prospect.shef.ac.uk/) is used to store all data for which the CTRU has data management responsibilities and any subsequent data analysis will use the data exported from the tables of the database to ASCII text files.  This means there is scope for streamlining the work flow by writing generalised functions to perform the tasks that are common across studies such as reading in files exported from Prospect and formatting factor variables and converting dates and that is the premise of the `ctru` package this vignette describes.

## Data Import

The starting point of any statistical analysis involves exporting the data from [Prospect](https://www.ctru-prospect.shef.ac.uk/) and importing it into R.

### Exporting from Prospect

Prospect provides some flexibility/options when exporting data such as whether numerical values should be exported for factor variables, including row numbers and formats for Boolean operators.  Whilst you are free to choose these options the following are suggested...

| Option                                                | Choice                      | Explanation                                |
|:------------------------------------------------------|:---------------------------:|:-------------------------------------------|
| Use numerical values for lookup lists                 | Yes                         | Export factor variables as numbers         |
| Include time/user stamps                              | No                          | Irrelevant to statistical analysis         |
| Include site column in events/forms/subforms          | Yes                         | Useful to have site information in all files|
| Include group column in events/forms/subforms         | Yes                         | Useful to have allocation in all files     |
| Include the row number of the subform                 | No                          | Irrelevant to statistical analysis         |
| Include verified column in forms/subforms             | No                          | Irrelevant to statistical analysis         |
| Remove line breaks                                    | Yes                         |                                            |
| Convert numeric string fields to Excel-friendly format| No                          | Not using Excel so irrelevant              |
| Include database IDs                                  | No                          | Irrelevant to statistical analysis         |
| Export blank strings as ""                            | Yes                         | Ensures blank strings are blank            |
| Date format						| yyyy-mm-dd                  | Conforms to ISO8601                        |
| Boolean format                                        | 1 = Ticked; 0 = Not ticked  | Ensures missing are blank                  |
| File format                                           | CSV                         | Output to ASCII text                       |
| Newline character                                     | CR+LF (\n\r)                | Universal carriage returns                 |
| Sites                                                 | All                         | Ensures data from all sites                |
| Study Data                                            | All                         | Exports all data                           |

The export will also include the file `Lookups.csv` and it is this file along with two other files extracted from the database specification that are used to facilitate importing and labelling data.

### Database Specification

Each database setup in Prospect has a matching *Data Specification* which is usually a Google Spreadsheet owned by a member of the Data Management Team and shared with the statistician.  Within these are two key worksheets `Fields` and `Forms` which describe all of the fields in the database and each of the tables (each table corresponds to a specific Case Report Form, hence the name `Forms`).

You should export both of these worksheets as ASCII CSV and save them in the same directory as the other files you have extracted from Prospect.  You will need to have *Edit* permission on the spreadsheet in order to be able to perform such an export.  If you do not have such permissions then request them from the document owner.

### Importing to R

You should now extract all files contained in the `.zip` that Prospect exported as well as `Fields.csv` and `Forms.csv` you saved from the Database Specification Googlesheet into the same directory.  This will include `Lookups.csv` which is the first file to be processed since it contains the dictionary for mapping encoded, numeric factor variables to their text description.  Start by processing it with `read_prospect()`

```{r}
## Create a list to store all objects in
master <- list()
## Read in the 'Lookups.csv' to this list
master$data.dictionary <- read_prospect(file       = 'Lookups.csv',
                                        header     = TRUE,
					sep        = ',',
					dictionary = NULL)
```

You now have the dictionary loaded into R that the `read_prospect()` function can subsequently use to encode factor variables.

```{r}
## Read in EQ5D data
master$eq5d <- read_prospect(file          = 'EQ-5D-5L.csv'
                             header        = TRUE,
                             sep           = ',',
			     convert.dates = TRUE,
                             dictionary    = master$data.dictionary)
## Read in Blood sample data
master$blood.sample <- read_prospect(file          = 'Blood sample.csv'
                                     header        = TRUE,
                                     sep           = ',',
				     convert.dates = TRUE,
                                     dictionary    = master$data.dictionary)
```

You can simplify this even further and reduce the time spent on reading your files in by utilising `lapply()` to work through a list of files in a given directory and have it apply `read_prospect()` to each file and return the results as a list...

**NB** The following has not been tested.

```{r}
## Read in all files in the current directory
master <- lapply(x = list.files("."),
                 read_prospect(file          = x,
		               header        = TRUE,
			       sep           = ',',
			       convert.dates = TRUE,
			       dictionary    = master$data.dictionary))
```


## Common Summaries & Analyses


### Screening and Randomisation

Every study screens and recruits individuals, often at multiple centers, to the study.  Details of screening and recruitment are recorded and it is usefl to include such information in the Statistical Analysis Report.

** ToDo ** Write how to use this function.

### Regression Modelling

A large number of studies assess the efficacy of an intervention by means of a regression model that allows the estimation of the effect an intervention has on the desired outcome whilst adjusting for co-variates and clustering (if a clustered study design is being utilised).  Invariably most analyses will be repeated twice, once using an Intention To Treat (ITT) cohort and once using a Per-Protocol (PP) cohort and it is natural to present the results of both simultaneously.  the `regress_ctru()` function is a wrapper that achieves this allowing arbitrary regression equations to be specified for a range of regression modelling functions.  It saves and returns the results of each model fit as well as combining them into formatted tables (LaTeX/HTML/ASCII) using the [Stargazer]() package.

** ToDo ** Write how to use this function.

## Writing Packages

A useful approach to working on a given project is to write an R package which contains all functions specific to your study.  This makes the statistical analysis self-contained as the package should include the data itself, the functions written to manipulate and analyse them and a literate method of collating all results into a document such as a PDF (using [Knitr](http://yihui.name/knitr/)) or website (using [Shiny](http://shiny.rstudio.com/))

The single best resource you can read to learn how to write R packages is Hadley Wickhams book *R packages* which is available [on-line for free](http://r-pkgs.had.co.nz/).

### Install requirements

You need to install the `devtools` package which will make writing packages and documenting them a *lot* easier.

```{r}
install.packages('devtools')
```


### Initialise a package

`devtools` has a number of functions to facilitate making a package, the first you will use is `devtools::create()` which takes one simple argument, the name of the package.

```{r}
devtools::create('my_package')
system('ls -l my_package')
-rw-r--r-- 1 you you  123 Mar  3 16:45 DESCRIPTION
drwxr-xr-x 1 you you 4096 Mar  3 16:45 man
drwxr-xr-x 1 you you 4096 Mar  3 16:45 R
```

You should now edit `DESCRIPTION` filling in the fields with the appropriate values and writing an informative description.  Its recommended to lazy load the data, and it is recommended to apply a copy-left license such as the [GPL-2](http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html) or [GPL-3](http://www.gnu.org/licenses/gpl-3.0.en.html) to your work so that others may freely use it (that is the intention of this work, to share it with others).

#### Include `ctru` and other packages as dependencies

Traditionally you might be used to writing R-scripts that at the start have a series of libraries loaded using `library()` this works for scripts but not for packages.  Instead you should list any package that yours depends on in the `DESCRIPTION` file under the `Depends:` section.  This means that when someone installs your package if a dependency is not present it will also be installed (similarly if you install this `ctru` package and do not have its dependencies installed they will be installed for you automatically).

At a bare minimum your Depends should read...

```{r}
Depends:
    R (>= 3.2.3),
    ctru (>= 0.0.0.9)
```

...but there are a large number of useful packages that you might commonly use so its worth including them.

```{r}
Depends:
    R (>= 3.2.3),
    ctru (>= 0.0.0.9),
    dplyr (>= 0.4.1),
    ggplot2 (>= 1.0.1),
    knitr (>= 1.11),
    lubridate (>= 1.5.0),
    magrittr (>= 1.5),
    reshape2 (),
    stargazer(>= 5.1),
    stringr (>= 1.0.0),
    texreg (>= 1.35),
    tidyr (>= 0.3.1),
    xtable (>= 1.7-4)
```
